{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNgdyZhFg57LBImYjbtjTXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarthikeyanBaskaran/Colab/blob/main/ColabCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM38GdJkOxsA",
        "outputId": "bd2c47d8-1006-4d9c-d714-45e07d3e3654"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!git clone https://github.com/KarthikeyanBaskaran/Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONOgZhgj3ndP",
        "outputId": "49e7fd7d-b357-4c56-a6f0-d495c08a2117"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'Colab'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 48 (delta 29), reused 23 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (48/48), 26.18 KiB | 6.54 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Colab/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu0heE6KFVAU",
        "outputId": "34cafb7d-7d5e-4950-80fd-c5cdf58eac3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N2XbsBLFGJc",
        "outputId": "2e217f19-7c5d-49cf-9328-e818b83d725b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "UEnjsnh-Unvj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w3voMDw2wWl",
        "outputId": "a479ebea-a80c-4c1e-a17f-792a0ad882a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-02 19:19:48,827 - INFO - NumExpr defaulting to 2 threads.\n",
            "2025-09-02 19:19:56.947950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756840796.965445     910 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756840796.971343     910 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756840796.986839     910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756840796.986866     910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756840796.986874     910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756840796.986878     910 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-02 19:19:56.991512: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-09-02 19:20:00,928 - INFO - TensorFlow version 2.19.0 available.\n",
            "2025-09-02 19:20:00,928 - INFO - JAX version 0.5.3 available.\n",
            "2025-09-02 19:20:03,578 - INFO - Use pytorch device_name: cuda:0\n",
            "2025-09-02 19:20:03,578 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "modules.json: 100% 349/349 [00:00<00:00, 3.22MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 1.25MB/s]\n",
            "README.md: 10.5kB [00:00, 49.0MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 617kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 6.70MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:00<00:00, 110MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 3.57MB/s]\n",
            "vocab.txt: 232kB [00:00, 11.6MB/s]\n",
            "tokenizer.json: 466kB [00:00, 38.6MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 1.20MB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.88MB/s]\n",
            "2025-09-02 19:20:06,866 - INFO - Loading configuration from 'config.yaml'...\n",
            "2025-09-02 19:20:06,867 - INFO - Loading raw resume text from 'Resume.yaml'...\n",
            "Paste the Job Description below. End with an empty line (just press Enter).\n",
            "About the job ROSEN is a global technology leader serving the oil & gas and engineering industries in over 120 countries. ROSEN Canada provides Asset Integrity Services nationwide, working collaboratively to deliver innovative solutions.   We are seeking a full-time Junior Data Analyst to join our Evaluation team in Calgary. In this role, you will analyze pipeline in-line inspection data, ensuring quality, accuracy, and efficiency using proprietary software, while meeting client reporting requirements.   Key Responsibilities  Assess, prepare, and process in-line inspection (ILI) data Integrate and verify supplementary data Categorize, evaluate, and size features Apply anomaly interaction rules and conduct standard/non-standard analysis Organize and deliver results per client specifications Maintain skills/training and support department goals   Qualifications  1–3 years’ data analysis experience  Post-secondary education or technical certification Strong troubleshooting, computer, and communication skills Detail-oriented, able to work independently and meet deadlines Ability to work flexible hours; occasional travel Must have valid Canadian work authorization and pass color vision testing   What We Offer  Competitive pay, benefits, RRSP matching, flexible hours, wellness program, professional development, and career growth opportunities.\n",
            "\n",
            "2025-09-02 19:20:23,230 - INFO - Semantic matching in progress\n",
            "Batches: 100% 1/1 [00:00<00:00,  1.54it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00,  5.87it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 26.21it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 108.37it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 56.03it/s]\n",
            "2025-09-02 19:20:24,189 - INFO - Contacting Groq API to generate tailored resume experience content...\n",
            "2025-09-02 19:20:24,882 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-09-02 19:20:26,055 - INFO - Successfully received initial experience content from Groq.\n",
            "2025-09-02 19:20:26,060 - INFO - Initial YAML from LLM is valid.\n",
            "2025-09-02 19:20:26,061 - INFO - 2. Contacting Groq API to generate tailored project content...\n",
            "2025-09-02 19:20:26,434 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-09-02 19:20:26,818 - INFO - Initial YAML from LLM is valid.\n",
            "Batches: 100% 1/1 [00:00<00:00, 175.54it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.01it/s]\n",
            "2025-09-02 19:20:26,833 - INFO - Saving final tailored YAML to 'output.yaml'...\n",
            "✅ Resume generated: Karthikeyan_Baskaran_Resume.pdf\n",
            "2025-09-02 19:20:26,865 - INFO - Extracting company and position names\n",
            "2025-09-02 19:20:30,386 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Resume saved as: Junior Data Analyst_Resume.pdf\n",
            "Job description saved as: job_description.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M1Uxg_SA2wTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd9436c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}